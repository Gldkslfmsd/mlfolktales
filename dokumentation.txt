ÄŒt dub 27 15:28:33 CEST 2017 [Dominik]

Classification
==============

Data description and preprocessing:
-- sie plots in plots/ dir
-- let's start only with English, there are enough labeled stories (342 in
total)
-- let's start with atu_level_1 due to lack of data
-- we split data by every category:
	-- 70 % of training
	-- 30 % of testing

	252:90
	
	
Feature selection:
-- most frequent words in each category
    -- remove diacritics and stopwords because they are the most frequent in all texts and we can't destinguish them by it
    -- take N mfw for each category
        -- remove the words which are in more than 1 groups
        -- estimate N by hand so every category has several such words
            -- we ended with 20
    -- make features from it:
        -- number of occurences in a text
        -- or number of occurences per word in a text
